# DQNエージェント 設定ファイル
# ファイル名は変更しないこと!

epsilon_init: 0.2 # ε-greedy法でランダムに行動を選択する確率。(初期値)
epsilon_diff: 0.001 # ε-greedy法でランダムに行動を選択する確率。(公差)
epsilon_min: 0.1 #ε-greedy法でランダムに行動を選択する確率。(最小値)
epsilon_decrement_step: 200 # ε-greedy法でεを減らし始めるステップ数。

gamma: 0.99 # 割引率。
alpha: 0.0015 # 学習率。
batch_size: 50 # Q Networkの学習時にサンプリングする経験の個数。
q_update_period: 10 # Q Networkを更新するステップ数の間隔。
target_update_period: 20 # Target Networkを更新するステップ数の間隔。

expbuf_capacity: 200 # 経験バッファの最大サイズ。

rmsprop_alpha: 0.95 # RMSPropの定数α。
rmsprop_epsilon: 0.01 # RMSPropの定数ε。

nn_type: FC # NNの種類。['FC', 'CNN']の中からいずれか1つを指定すること。
